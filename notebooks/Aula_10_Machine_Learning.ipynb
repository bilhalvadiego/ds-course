{"cells":[{"metadata":{"id":"5yCVw1u_wULU","slideshow":{"slide_type":"skip"}},"cell_type":"markdown","source":"[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/billy-ds/ds-course.git/prod?filepath=notebooks%2FAula_10_Machine_Learning.ipynb)\n<br>\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/billy-ds/ds-course/blob/prod/notebooks/Aula_10_Machine_Learning.ipynb)"},{"metadata":{"id":"14pGVPAPwULZ","slideshow":{"slide_type":"skip"}},"cell_type":"markdown","source":"<a id='section-zero'></a>"},{"metadata":{"id":"lNZiWaqswULa","slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"# *Machine Learning*\n\n**Objetivos**: Aprender o que é *Machine Learning* e quais são os componentes de um algoritmo de ML."},{"metadata":{"id":"gbJm5VXJwULa","slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"## Defininição - *Machine Learning*\n\n*Machine Learning* é uma área de estudo que fornece aos computadores a habilidade de aprender sem serem explicitamente programados.\n\n> Um programa de computador que aprende a partir da experiência E em relação a algum tipo de tarefa T e alguma medida de desempenho P, se o seu desempenho em T, conforme medido por P, melhora com a experiência E.\n\nMitchell, T. M. (1997). Machine Learning. McGraw-Hill, New York."},{"metadata":{"id":"CiFyB-pgwULb","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"### Experiência (E)\n\nEm *Machine Learning* um programa de computador aprende sem ser explicitamente programado. Ele aprende a partir de um conjunto de dados que expressa toda *experiência* (E) que desejamos ensiná-lo. Esse conjunto de dados é chamado de **conjunto de treinamento**. \n\n* **Aprendizagem Supervisionada**: o conjunto de treinamento é composto por amostras de entradas/saídas.\n* **Aprendizagem Não-Supervisionada**:  conjunto de treinamento é composto por amostras de entradas apenas.\n* ~~Aprendizagem por Reforço~~"},{"metadata":{"id":"u0-y1HDlwULc","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"### Tarefas (T)\n\n* Classificação - Supervisionada qualitativa\n* Regressão - Supervisionada quantitativa\n* Agrupamento - Não-supervisionada"},{"metadata":{"id":"VSmkU0EXwULd","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"#### Tente responder: Classifique as sentenças a baixo como: Aprendizagem supervisionada (classifição ou regressão) ou não-supervisionada\n* Estimar o preço de uma casa?\n* Agrupar notícias semelhantes publicadas por várias fontes de informação?\n* Estimar o número de compartilhamentos em redes sociais de notícias?\n* Determinar se uma pessoa tem câncer benigno ou maligno?\n* Identificar padrões de navegação em sites?\n* Determinar se um texto publicado em uma rede social é inadequado ou não?"},{"metadata":{"id":"sKVJozszwULe","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"### Desempenho (P)\n\nPara medir o desempenho de um algoritmo de Machine Learning é preciso de uma medida de desempenho para mensurar a qualidade do processo de aprendizagem. Essa medida é conhecida como **função de custo** ou **função de erro**. Essa função é definida de acordo com o tipo de problema (aprendizagem supervisionada ou não-supervisionada). Essa função contém um **conjunto de parâmetros** a serem otimizados pelo um algoritmo de *Machine Learning*.\n\nDe maneira geral, pode-se dizer que o objetivo do algoritmo de *Machine Learning* é otimizar (aprender) o **conjunto de parâmetros** de tal forma que resultado da função seja o mínimo possível. Isso significa que algoritmo tem uma alta taxa de aprendizagem e uma baixa taxa de erro.\n\n* Dividir os dados em\n* Treino\n* Teste\n    * Aqui eu mensuro desempenho (P)"},{"metadata":{"id":"ZQmOMJquwULf","slideshow":{"slide_type":"fragment"}},"cell_type":"markdown","source":"<img src=\"https://github.com/billy-ds/ds-course/blob/prod/notebooks/images/train-test.png?raw=1\" alt=\"train-test\" style=\"width: 60%;\"/>"},{"metadata":{"id":"VhXIxEaLwULg","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"### Exemplo: jogo de computador\n- Tarefa $T$ é jogar xadrez. \n- Medida de desempenho $P$ é uma relação entre partidas ganhas contra oponentes versus perdidas. \n- Experiência $E$ é prática de partidas concluídas. Note que, estas experiências são descritas em um conjunto de dados chamado de **conjunto de treinamento**."},{"metadata":{"id":"vgnLOJqZwULh","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"#### Tente responder: Classifique as sentenças a baixo como: Tarefa $T$, Experiências $E$ e Medida de desempenho $P$\n\n- Classificar emails como spam ou não spam ?\n- Verificar quais emails o algoritmo classifica como spam ?\n- O número (ou fração) de emails corretamente classificados como spam ou não spam ?"},{"metadata":{"id":"SbZdJjiSwULh","slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"## Generalização\n\nA habilidade de desempenhar bem em dados não observados anteriormente.\n\nMensurada por erro:\n* Dados de Treino: Erro de Treino\n* Dados de Teste: Erro de Teste"},{"metadata":{"id":"P50I39rxwULi","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"### Erro do Algoritmo\n\n2 Fatores:\n\n1. Habilidade de Reduzir o Erro de Treino\n2. Habilidade de Reduzir a Lacuna entre o Erro de Treino e o Erro de Teste\n\n<img src=\"https://github.com/billy-ds/ds-course/blob/prod/notebooks/images/train-vs-test-error.png?raw=1\" alt=\"train-vs-test-error\" style=\"width: 60%;\"/>"},{"metadata":{"id":"Xk1c9_F_wULi","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"<img src=\"https://github.com/billy-ds/ds-course/blob/prod/notebooks/images/trainin4.gif?raw=1\" alt=\"training\" style=\"width: 60%;\"/>"},{"metadata":{"id":"iRTkNg4fwULj","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"### *Overfitting* e *Underfitting*\n\n* Centrais em *Machine Learning*\n* Underfitting\n    - Modelos **menos** flexíveis que o ideal\n* Overfitting\n    - Modelos **mais** flexíveis que o ideal   \n\n<img src=\"https://github.com/billy-ds/ds-course/blob/prod/notebooks/images/underfitting-overfitting-capacity.png?raw=1\" alt=\"underfitting-overfitting-capacity\" style=\"width: 60%;\"/>"},{"metadata":{"id":"DBGzv2U-wULj","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"#### No Free Lunch Theorem (NFL)\n\n> “Se você faz nenhum pressuposto dos dados, não há razão para preferir um modelo por outro”\n\n> Wolpert, D. H. (1996). The Lack of a Priori Distinctions between Learning Algorithms. Neural Computation, 8(7), 1341–1390. https://doi.org/10.1162/neco.1996.8.7.1341\n\t\n* Nenhum modelo é garantido que funcionará melhor\n    * Ex: para alguns dados, regressão linear é melhor; para outros, redes neurais.\n* A única maneira de saber é avaliar todos os modelos\n* Por isso que não há *almoço grátis*"},{"metadata":{"id":"Sh0t54MDwULk","slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"## Otimização\n\nMétodo mais utilizado é o **Método do Gradiente** (*Gradient Descent*)\n\nInventado em 1847 por Augustin-Louis Cauchy. Usa a derivativa para minimizar uma função-alvo.\n\n**Método iterativo**: a cada iteração, tenta ir para o local/global minima\n\n<img src=\"https://github.com/billy-ds/ds-course/blob/prod/notebooks/images/gradient-descent.png?raw=1\" alt=\"gradient-descent\" style=\"width: 60%;\"/>"},{"metadata":{"id":"5DzYjju4wULk","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"<img src=\"https://github.com/billy-ds/ds-course/blob/prod/notebooks/images/gradient-descent.gif?raw=1\" alt=\"gradient-descent-animation\" style=\"width: 60%;\"/>"},{"metadata":{"id":"Cm28CYxAwULk","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"<img src=\"https://github.com/billy-ds/ds-course/blob/prod/notebooks/images/gradient-descent-2.gif?raw=1\" alt=\"gradient-descent-animation\" style=\"width: 60%;\"/>"},{"metadata":{"id":"ctjzKL8kwULl","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"### Local/Global Minima/Maxima\n\n<img src=\"https://github.com/billy-ds/ds-course/blob/prod/notebooks/images/local-minima.png?raw=1\" alt=\"local-minima\" style=\"width: 60%;\"/>"},{"metadata":{"id":"iymyok1AwULl","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"<img src=\"https://github.com/billy-ds/ds-course/blob/prod/notebooks/images/gradient-descent-1.gif?raw=1\" alt=\"gradient-descent-animation-2\" style=\"width: 60%;\"/>"},{"metadata":{"id":"k6_3gRXbwULl","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"<img src=\"https://github.com/billy-ds/ds-course/blob/prod/notebooks/images/gradient-descent-3.gif?raw=1\" alt=\"gradient-descent-animation-3\" style=\"width: 60%;\"/>"},{"metadata":{"id":"HzkAQdB3wULm","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"### Tipos de Método do Gradiente (*Gradient Descent*)\n\n* *Batch Gradient Descent*: Dataset todo\n* *Stochastic Gradient Descent*: Um exemplo aleatório do Dataset\n* *Mini-batch Gradient Descent*: Amostras aleatórias do Dataset"},{"metadata":{"id":"ZxDDDs12wULm","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"\n<img src=\"https://github.com/billy-ds/ds-course/blob/prod/notebooks/images/grad-descent-methods.png?raw=1\" alt=\"grad-descent-methods\" style=\"width: 60%;\"/>"},{"metadata":{"id":"lJrmk2AKwULm","slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"## Scikit-Learn"},{"metadata":{"id":"VuPCackhwULm","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"Você deve \"treinar\" o seu estimador do `sklearn` nos dados de treino e mensurar o desempenho nos dados de teste.\n\n1. Instancia um objeto de um estimador do `sklearn`. Tradicionalmente regressores e classificadores ambos são instanciados como `clf`:\n    ```python\n    from sklearn.MODULO import ESTIMADOR\n    clf = ESTIMADOR()\n    ```\n2. Treinar o estimador com os dados de treino usando o método `.fit()`:\n    ```python\n    clf.fit(X_train, y_train)\n    ```\n3. Mensurar o desempenho do estimador treinado nos dados de teste usando o método `.score()`:\n    ```python\n    clf.score(X_test, y_test)\n    ```"},{"metadata":{"id":"bDniC4VNwULn","slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"### Como preparar um dataset do Pandas para um modelo de aprendizagem supervisionada do Scikit-Learn"},{"metadata":{"id":"EazS5FGVwULn","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"Lembrando que o nosso dataset do pandas possui todos os atributos `X` (variáveis / *features*) que usaremos na estimação da resposta `y`.\n\n* `X` são as variáveis **sem a resposta `y`**: `X = df.drop(['variavel_resposta'])`\n* `y` é **apenas a variável resposta `y`**: `y = df['variavel_resposta']`"},{"metadata":{"id":"juWkSg7VwULn","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"> Mas, professor... E os dados de **treino** e de **teste**?"},{"metadata":{"id":"UK5Kkk4PwULo","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"O Scikit-Learn tem uma função que divide automaticamente de maneira aleatória em dados de **treino** e dados de **teste**. Esta função chama-se `train_test_split()`. Ela aceita uma matriz e retorna duas matrizes uma de treino e uma de teste. Além disso, pode-se especificar o tamanho da quebra em pontos percentuais (ex: `0.33` quebra o dataset em 67% treino e 33% teste). Para replicabilidade, pode-se especificar também uma *seed* do gerador de número aleatórios que aceita um número inteiro como *seed*.\n\n> Obs: O `train_test_split()` aceita múltiplas matrices/tabelas para quebrar em treino/teste só tome cuidado com o tamanho da lista que a função retornará."},{"metadata":{"id":"atbDkS3-wULo","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"```python\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=42)\n```"},{"metadata":{"id":"Kz4FNWXMwULo","slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"### Como *Treinar* um modelo de aprendizagem supervisionada no Scikit-Learn"},{"metadata":{"id":"UR90LviKwULo","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"Ao quebrar `X` e `y` em `X_train`, `X_test`, `y_train`, `y_test`, você obterá as seguintes variáveis:\n* `X_train`: atributos dos meus dados de treino\n* `y_train`: resposta dos meus dados de treino\n* `X_teste`: atributos dos meus dados de teste\n* `y_teste`: resposta dos meus dados de teste"},{"metadata":{"id":"lmWIGyHAwULo","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"```python\n# Regressor\ny_pred = clf.predict(X_test)\nsklearn.metrics.r2_score(y_test, y_pred)\n```\n```python\n# Classificador\ny_pred = clf.predict(X_test)\nsklearn.metrics.accuracy_score(y_test, y_pred)\n```\n\n```python\nclf.score(X_test, y_test)\n```"},{"metadata":{"id":"5qzWS-rQwULp","slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"### Métricas de Desempenho Padrões do Scikit-Learn\n\n* **Regressor**: $R^2$ do estimador - O quanto (em porcentagem) de variação da resposta `y` é \"capturado\" pelos atributos `X` do estimador - `Float` entre $0$ e $1$\n  \n  > O $R^2$ é uma medida estatística de quão próximos os dados estão da linha de regressão ajustada. Ele também é conhecido como o coeficiente de determinação ou o coeficiente de determinação múltipla para a regressão múltipla.\n\n* **Classificador**: Acurácia do estimador - O quanto (em porcentagem) o estimador acerta das classes da resposta `y` - `Float` entre $0$ e $1$"},{"metadata":{"id":"u0fawPJ6wULp","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"Estimador do Scikit-Learn: `clf`\n\n* **Estimar** (Aprenda com os dados): `clf.fit(X, y)`\n    * `X`: `DataFrame` Pandas ou `ndarray` NumPy (sem a variável que você quer prever - resposta) com linhas como observações e colunas como variáveis (atributos - *features*)\n    * `y`: `Series` Pandas ou `ndarray` NumPy da variável de interesse resposta que deve ter o mesmo número observações que `X`\n* **Métricas de Desempenho**: `clf.score(X, y)`\n    * Classificação: Acurácia\n    * Regressão: $R^2$ -  O quanto de variação da resposta que o seu estimador consegue \"explicar\"\n* **Prever** uma resposta `y_new` a partir de **novos dados** `X_new` não-observados no treinamento: `y_new = clf.predict(X_new)`"},{"metadata":{"id":"8JsCnlqVwULp","slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"## Atividade\n\n1. Traga 2 exemplos de Tarefa Supervisionada\n2. Traga 2 exemplos de Tarefa Não-Supervisionada"},{"metadata":{"id":"uQQuFY5vwULq","slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"**Ir para o** [Início](#section-zero) | **Próximo Tópico:** [Regressão Linear](https://mybinder.org/v2/gh/billy-ds/ds-course.git/prod?filepath=notebooks%2FAula_11_Regressao_Linear.ipynb)"}],"metadata":{"celltoolbar":"Slideshow","kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.10.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"rise":{"autolaunch":true,"enable_chalkboard":true,"progress":true,"scroll":true,"slideNumber":true,"theme":"white"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":1}
